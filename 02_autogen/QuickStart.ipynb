{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autogen QuickStart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/agents.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY 들이 저장된 .env 파일을 읽고 환경 변수로 등록합니다.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 이 사용할 Tool 함수를 선언합니다.\n",
    "# 여기서는 간단한 예시로 지정된 문자열을 반환합니다.\n",
    "async def web_search(query: str) -> str:\n",
    "    \"\"\"Find information on the web\"\"\"\n",
    "    return \"AutoGen is a programming framework for building multi-agent applications.\"\n",
    "\n",
    "\n",
    "# 사용할 LLM 모델을 설정합니다.\n",
    "# API KEY 를 .env 에서 로드했으면, api_key 는 자동으로 입력됩니다.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    # api_key=\"YOUR_API_KEY\",\n",
    ")\n",
    "\n",
    "# Agent 를 선언합니다.\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[web_search],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolCallRequestEvent(source='assistant', models_usage=RequestUsage(prompt_tokens=61, completion_tokens=16), content=[FunctionCall(id='call_aEjvy792Nn0b369EMqoa3ZSb', arguments='{\"query\":\"AutoGen\"}', name='web_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant', models_usage=None, content=[FunctionExecutionResult(content='AutoGen is a programming framework for building multi-agent applications.', call_id='call_aEjvy792Nn0b369EMqoa3ZSb')], type='ToolCallExecutionEvent')]\n",
      "source='assistant' models_usage=None content='AutoGen is a programming framework for building multi-agent applications.' type='ToolCallSummaryMessage'\n"
     ]
    }
   ],
   "source": [
    "# 준비된 Agent 를 실행시킵니다.\n",
    "async def assistant_run() -> None:\n",
    "    response = await agent.on_messages(\n",
    "        [TextMessage(content=\"Find information on AutoGen\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "    print(response.inner_messages)\n",
    "    print(response.chat_message)\n",
    "\n",
    "\n",
    "# Use asyncio.run(assistant_run()) when running in a script.\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- assistant ----------\n",
      "[FunctionCall(id='call_md4te6nAQyYN3fA5LpILHInn', arguments='{\"query\":\"AutoGen multi-agent framework\"}', name='web_search')]\n",
      "---------- assistant ----------\n",
      "[FunctionExecutionResult(content='AutoGen is a programming framework for building multi-agent applications.', call_id='call_md4te6nAQyYN3fA5LpILHInn')]\n",
      "---------- assistant ----------\n",
      "AutoGen is a programming framework for building multi-agent applications.\n"
     ]
    }
   ],
   "source": [
    "# 준비된 Agent 를 Stream 방식으로 실행시킵니다.\n",
    "# 단계별 메시지 흐름을 파악하기에 유용합니다.\n",
    "async def assistant_run_stream() -> None:\n",
    "\n",
    "    await Console(\n",
    "        agent.on_messages_stream(\n",
    "            [TextMessage(content=\"Find information on AutoGen\", source=\"user\")],\n",
    "            cancellation_token=CancellationToken(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Use asyncio.run(assistant_run_stream()) when running in a script.\n",
    "await assistant_run_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogenstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
